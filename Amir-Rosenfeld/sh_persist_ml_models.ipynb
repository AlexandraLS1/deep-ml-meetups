{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist models POC using sk-learn + Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "!pip install psycopg2\n",
    "import psycopg2 as pg\n",
    "import psycopg2.extras\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.line_width', 200)\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os,sys,inspect\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from scipy.stats import norm, invgamma\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import numpy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "from sqlalchemy import Column, Integer, Text\n",
    "from sqlalchemy.dialects.postgresql import JSON, JSONB\n",
    "from sqlalchemy import Table, Column, Sequence, Integer, String, Float, DateTime, ForeignKey, and_\n",
    "from sqlalchemy.orm import relationship, backref, sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm.collections import attribute_mapped_collection\n",
    "from sqlalchemy.dialects.postgresql import ARRAY\n",
    "from sqlalchemy.ext.associationproxy import association_proxy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# sns.set(style='ticks', context='talk')\n",
    "# ! df -k\n",
    "# ! pwd\n",
    "\n",
    "import keras\n",
    "print('keras: ', keras.__version__)\n",
    "\n",
    "# optional\n",
    "import theano\n",
    "print('Theano: ', theano.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def gridBestParams(train_X, train_y, modelType, folds=5, verbose=False):\n",
    "    print('running grid:' + str(modelType))\n",
    "\n",
    "    params_lr = {'penalty': ['l2'], 'C': [0.0001, 0.001, 0.1, 0.01, 1, 2, 5],\n",
    "                 'solver': ['newton-cg'],\n",
    "                 'fit_intercept': [False, True]}   \n",
    "    model_lg = LogisticRegression()\n",
    "    \n",
    "    if modelType == 'lr':\n",
    "        method = model_lg\n",
    "        params = params_lr\n",
    "    \n",
    "    print('running grid:' + str(params))\n",
    "\n",
    "    gscv = GridSearchCV(method, params, scoring='neg_log_loss', cv=folds, verbose=verbose)\n",
    "    gscv.fit(train_X, train_y)\n",
    "    for params, mean_score, all_scores in gscv.grid_scores_:\n",
    "        print('{:.6f} (+/- {:.6f}) for {}'.format(mean_score, all_scores.std() / 2, params))\n",
    "    print('params:{params}'.format(params=gscv.best_params_))\n",
    "    print('score:{params}'.format(params=gscv.best_score_))\n",
    "    return gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_model_table\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "def connect(user, password, db, host='localhost', port=5432):\n",
    "    '''Returns a connection and a metadata object'''\n",
    "    # We connect with the help of the PostgreSQL URL\n",
    "    # postgresql://federer:grandestslam@localhost:5432/tennis\n",
    "    url = 'postgresql://{}:{}@{}:{}/{}'\n",
    "    url = url.format(user, password, host, port, db)\n",
    "\n",
    "    # The return value of create_engine() is our connection object\n",
    "    con = sqlalchemy.create_engine(url, client_encoding='utf8')\n",
    "\n",
    "    # We then bind the connection to MetaData()\n",
    "    meta = sqlalchemy.MetaData(bind=con, reflect=True)\n",
    "\n",
    "    return con, meta\n",
    "\n",
    "user = 'docker'\n",
    "password = 'docker'\n",
    "db_host = \"localhost\"\n",
    "port = 5432\n",
    "name = 'docker'\n",
    "db_url = \"postgresql://%s:%s@%s:%s/%s\" % (user, password, db_host, port, name) \n",
    "\n",
    "db = sqlalchemy.create_engine(db_url, convert_unicode=True, client_encoding='utf8')\n",
    "engine = db.connect()\n",
    "meta = sqlalchemy.MetaData(engine)\n",
    "\n",
    "# con, meta = connect('postgres', 'postgres', 'sleep_ml')\n",
    "\n",
    "# connection_string = 'postgresql:///sleep_ml'\n",
    "# db = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "from sqlalchemy import inspect\n",
    "inspector = inspect(db)\n",
    "for _t in inspector.get_table_names(): print _t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import PickleType\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "from datetime import datetime\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class ML_MODEL(Base):\n",
    "    __tablename__ = 'ml_model_table'           \n",
    "    id = Column(Integer, Sequence(\"ml_id_seq\"), primary_key=True)\n",
    "    ml_algo=Column(String, nullable=False)\n",
    "    tstamp=Column(DateTime, default=datetime.utcnow)\n",
    "    accuracy=Column(Float, nullable=False)\n",
    "    LOG_LOSS=Column(Float, nullable=False)\n",
    "    ROC_AUC=Column(Float, nullable=False)\n",
    "    s_size=Column(Float, nullable=False)    \n",
    "    version=Column(String, nullable=False)\n",
    "#     ml_opt=Column(JSON, nullable=False)\n",
    "    ml_pickle = Column(PickleType)\n",
    "    k_fold=Column(Float, nullable=False)\n",
    "#     ml_json=Column(JSON, nullable=False)\n",
    "    ml_grid_search=Column(JSON, nullable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57771,)\n",
      "(57771, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "# names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "# dataframe = pandas.read_csv(url, names=names)\n",
    "# array = dataframe.values\n",
    "# X = array[:,0:8]\n",
    "# Y = array[:,8]\n",
    "# test_size = 0.33\n",
    "\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.preprocessing import PolynomialFeatures, Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train = pd.read_csv(\"numerai_training_data.csv\")\n",
    "combined = pd.read_csv(\"numerai_tournament_data.csv\")\n",
    "\n",
    "# Seperate training data from test data\n",
    "merged = combined.merge(train, how='left', indicator=True)\n",
    "test = combined[merged['_merge'] == 'left_only']\n",
    "\n",
    "# Seperate the target data and test_id to create clean target and features\n",
    "target = train['target']\n",
    "t_id = test['t_id']\n",
    "t_id.reset_index(drop=True, inplace=True)\n",
    "\n",
    "del train['target']\n",
    "del test['t_id']\n",
    "\n",
    "print (target.shape)\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...:0\n",
      "ACC=0.526042486231\n",
      "ROC_AUC=0.52471629018\n",
      "LOG_LOSS=16.3701460511\n",
      "Starting ...:1\n",
      "ACC=0.514240755311\n",
      "ROC_AUC=0.513831344693\n",
      "LOG_LOSS=16.7777755382\n",
      "Starting ...:2\n",
      "ACC=0.521164437451\n",
      "ROC_AUC=0.519369957626\n",
      "LOG_LOSS=16.53862795\n",
      "Starting ...:3\n",
      "ACC=0.523682140047\n",
      "ROC_AUC=0.521902292264\n",
      "LOG_LOSS=16.4516687023\n",
      "Starting ...:4\n",
      "ACC=0.525413060582\n",
      "ROC_AUC=0.523115368555\n",
      "LOG_LOSS=16.3918804212\n",
      "Starting ...:5\n",
      "ACC=0.526907946499\n",
      "ROC_AUC=0.52469839063\n",
      "LOG_LOSS=16.3402470035\n",
      "Starting ...:6\n",
      "ACC=0.52321007081\n",
      "ROC_AUC=0.522249819426\n",
      "LOG_LOSS=16.4679807567\n",
      "Starting ...:7\n",
      "ACC=0.516207710464\n",
      "ROC_AUC=0.514487702864\n",
      "LOG_LOSS=16.7098268576\n",
      "Starting ...:8\n",
      "ACC=0.526121164437\n",
      "ROC_AUC=0.524008805613\n",
      "LOG_LOSS=16.3674193542\n",
      "Starting ...:9\n",
      "ACC=0.525098347758\n",
      "ROC_AUC=0.522589822679\n",
      "LOG_LOSS=16.4027507833\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    engine.execute('drop table ml_model_table')\n",
    "except:\n",
    "    print \"Table exists,ignoring error ... \"        \n",
    "                \n",
    "Base.metadata.create_all(bind=db)\n",
    "Session = sessionmaker()\n",
    "Session.configure(bind=db)\n",
    "session = Session()\n",
    "\n",
    "k_folds=5\n",
    "for num in range(0,10):\n",
    "        print ('Starting ...:' + str(num))\n",
    "        seed = num\n",
    "#         X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(train, target, test_size=0.22, random_state=seed)\n",
    "#         lr_best_params = gridBestParams (X_train, Y_train, modelType='lr', folds=k_folds)\n",
    "\n",
    "        lr_best_params = {'penalty': 'l2', 'C': 0.0001, 'solver': 'newton-cg', 'fit_intercept': False}\n",
    "#         model = LogisticRegression(**lr_best_params)\n",
    "        model = LogisticRegression()\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        # save the model to disk\n",
    "        s = pickle.dumps(model)\n",
    "\n",
    "        predicted = model.predict(X_test)\n",
    "        print('ACC=' + str(metrics.accuracy_score(Y_test, predicted)))\n",
    "        print('ROC_AUC=' + str((metrics.roc_auc_score(Y_test, predicted))))\n",
    "        print('LOG_LOSS=' + str(metrics.log_loss(Y_test, predicted)))                   \n",
    "\n",
    "        u = ML_MODEL(            \n",
    "        accuracy=metrics.accuracy_score(Y_test, predicted),\n",
    "        LOG_LOSS = metrics.log_loss(Y_test, predicted),\n",
    "        ROC_AUC=metrics.roc_auc_score(Y_test, predicted),\n",
    "        s_size=num,\n",
    "        ml_algo=str(model),    \n",
    "        version='JENKINS_' + str(num), \n",
    "#         ml_opt=\"{c='1'}\",\n",
    "        ml_pickle=s,\n",
    "        k_fold=k_folds,        \n",
    "        ml_grid_search=lr_best_params)\n",
    "        session.add(u)    \n",
    "        session.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Model History + Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ml_algo</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>LOG_LOSS</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>s_size</th>\n",
       "      <th>version</th>\n",
       "      <th>ml_pickle</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>ml_grid_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:54.332155</td>\n",
       "      <td>0.514241</td>\n",
       "      <td>16.777776</td>\n",
       "      <td>0.513831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JENKINS_1</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:56.204342</td>\n",
       "      <td>0.516208</td>\n",
       "      <td>16.709827</td>\n",
       "      <td>0.514488</td>\n",
       "      <td>7.0</td>\n",
       "      <td>JENKINS_7</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:54.765166</td>\n",
       "      <td>0.521164</td>\n",
       "      <td>16.538628</td>\n",
       "      <td>0.519370</td>\n",
       "      <td>2.0</td>\n",
       "      <td>JENKINS_2</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:55.066837</td>\n",
       "      <td>0.523682</td>\n",
       "      <td>16.451669</td>\n",
       "      <td>0.521902</td>\n",
       "      <td>3.0</td>\n",
       "      <td>JENKINS_3</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:55.982325</td>\n",
       "      <td>0.523210</td>\n",
       "      <td>16.467981</td>\n",
       "      <td>0.522250</td>\n",
       "      <td>6.0</td>\n",
       "      <td>JENKINS_6</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:56.737798</td>\n",
       "      <td>0.525098</td>\n",
       "      <td>16.402751</td>\n",
       "      <td>0.522590</td>\n",
       "      <td>9.0</td>\n",
       "      <td>JENKINS_9</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:55.395870</td>\n",
       "      <td>0.525413</td>\n",
       "      <td>16.391880</td>\n",
       "      <td>0.523115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>JENKINS_4</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:56.503676</td>\n",
       "      <td>0.526121</td>\n",
       "      <td>16.367419</td>\n",
       "      <td>0.524009</td>\n",
       "      <td>8.0</td>\n",
       "      <td>JENKINS_8</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:55.679785</td>\n",
       "      <td>0.526908</td>\n",
       "      <td>16.340247</td>\n",
       "      <td>0.524698</td>\n",
       "      <td>5.0</td>\n",
       "      <td>JENKINS_5</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>2017-05-07 06:02:54.001917</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>16.370146</td>\n",
       "      <td>0.524716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>JENKINS_0</td>\n",
       "      <td>ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.0001, u'solver': u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            ml_algo                     tstamp  accuracy   LOG_LOSS   ROC_AUC  s_size    version                                          ml_pickle  k_fold                                     ml_grid_search\n",
       "0  31  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:54.332155  0.514241  16.777776  0.513831     1.0  JENKINS_1  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "1  37  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:56.204342  0.516208  16.709827  0.514488     7.0  JENKINS_7  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "2  32  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:54.765166  0.521164  16.538628  0.519370     2.0  JENKINS_2  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "3  33  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:55.066837  0.523682  16.451669  0.521902     3.0  JENKINS_3  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "4  36  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:55.982325  0.523210  16.467981  0.522250     6.0  JENKINS_6  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "5  39  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:56.737798  0.525098  16.402751  0.522590     9.0  JENKINS_9  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "6  34  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:55.395870  0.525413  16.391880  0.523115     4.0  JENKINS_4  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "7  38  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:56.503676  0.526121  16.367419  0.524009     8.0  JENKINS_8  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "8  35  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:55.679785  0.526908  16.340247  0.524698     5.0  JENKINS_5  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u...\n",
       "9  30  LogisticRegression(C=1.0, class_weight=None, d... 2017-05-07 06:02:54.001917  0.526042  16.370146  0.524716     0.0  JENKINS_0  ccopy_reg\\n_reconstructor\\np0\\n(csklearn.linea...     5.0  {u'penalty': u'l2', u'C': 0.0001, u'solver': u..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = session.query(ML_MODEL).order_by(ML_MODEL.ROC_AUC)\n",
    "df = pd.read_sql(query.statement, query.session.bind)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_model_table\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "inspector = inspect(db)\n",
    "for _t in inspector.get_table_names(): print _t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook sh_persist_ml_models.ipynb to slides\n",
      "[NbConvertApp] Writing 310169 bytes to sh_persist_ml_models.slides.html\n",
      "[NbConvertApp] Redirecting reveal.js requests to https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.1.0\n",
      "Serving your slides at http://127.0.0.1:8000/sh_persist_ml_models.slides.html\n",
      "Use Control-C to stop this server\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert sh_persist_ml_models.ipynb --to slides --post serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
